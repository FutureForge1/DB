"""
ç»Ÿä¸€SQLåˆ†æå™¨
æ ¹æ®SQLè¯­å¥ç±»å‹è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„åˆ†æå™¨ï¼ˆSELECTã€DDLã€DMLï¼‰
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from typing import List, Optional, Tuple
from src.common.types import Token, TokenType, SyntaxError, ASTNode
from src.compiler.lexer.lexer import Lexer
from src.compiler.parser.parser import Parser
from src.compiler.parser.extended_parser import ExtendedParser
from src.compiler.parser.ddl_parser import DDLParser
from src.compiler.parser.dml_parser import DMLParser

class UnifiedSQLParser:
    """ç»Ÿä¸€SQLåˆ†æå™¨"""
    
    def __init__(self, sql: str):
        """
        åˆå§‹åŒ–ç»Ÿä¸€SQLåˆ†æå™¨
        
        Args:
            sql: SQLè¯­å¥å­—ç¬¦ä¸²
        """
        self.sql = sql
        self.tokens = []
        self.sql_type = None
        self.parser = None
    
    def parse(self) -> Tuple[Optional[ASTNode], str]:
        """
        è§£æSQLè¯­å¥
        
        Returns:
            (ASTæ ¹èŠ‚ç‚¹, SQLç±»å‹)
        """
        try:
            # 1. è¯æ³•åˆ†æ
            lexer = Lexer(self.sql)
            self.tokens = lexer.tokenize()
            
            if not self.tokens:
                return None, "EMPTY"
            
            # 2. ç¡®å®šSQLç±»å‹
            self.sql_type = self._determine_sql_type()
            
            # 3. é€‰æ‹©åˆé€‚çš„åˆ†æå™¨
            if self.sql_type == "SELECT":
                return self._parse_select(), self.sql_type
            elif self.sql_type == "DDL":
                return self._parse_ddl(), self.sql_type
            elif self.sql_type == "DML":
                return self._parse_dml(), self.sql_type
            else:
                self._provide_sql_suggestion(self.sql_type)
                raise SyntaxError(f"ä¸æ”¯æŒçš„SQLè¯­å¥ç±»å‹: {self.sql_type}")
                
        except SyntaxError as e:
            # ä¿ç•™åŸå§‹çš„è¯­æ³•é”™è¯¯ä¿¡æ¯
            raise e
        except Exception as e:
            raise SyntaxError(f"SQL parsing failed: {e}")
    
    def _determine_sql_type(self) -> str:
        """
        æ ¹æ®ç¬¬ä¸€ä¸ªå…³é”®å­—ç¡®å®šSQLç±»å‹
        
        Returns:
            SQLç±»å‹å­—ç¬¦ä¸²
        """
        if not self.tokens or self.tokens[0].type == TokenType.EOF:
            return "EMPTY"
        
        first_token = self.tokens[0]
        
        # SELECTæŸ¥è¯¢
        if first_token.type == TokenType.SELECT:
            return "SELECT"
        
        # DDLè¯­å¥ï¼ˆå«äº‹åŠ¡æ§åˆ¶ï¼‰
        if first_token.type in [TokenType.CREATE, TokenType.DROP, TokenType.ALTER, TokenType.SHOW,
                                 TokenType.BEGIN, TokenType.COMMIT, TokenType.ROLLBACK]:
            return "DDL"
        
        # DMLè¯­å¥
        if first_token.type in [TokenType.INSERT, TokenType.UPDATE, TokenType.DELETE]:
            return "DML"
        
        return "UNKNOWN"
    
    def _provide_sql_suggestion(self, sql_type: str):
        """ä¸ºæ— æ³•è¯†åˆ«çš„SQLæä¾›å»ºè®®"""
        if not self.tokens:
            print("ğŸ’¡ æç¤º: è¯·è¾“å…¥æœ‰æ•ˆçš„SQLè¯­å¥")
            return
            
        first_token = self.tokens[0].value.upper()
        suggestions = {
            'SELEC': 'SELECT',
            'FORM': 'FROM', 
            'WERE': 'WHERE',
            'CREAT': 'CREATE',
            'DELET': 'DELETE',
            'UPDAT': 'UPDATE',
            'INSER': 'INSERT'
        }
        
        if first_token in suggestions:
            print(f"ğŸ’¡ æç¤º: æ‚¨æ˜¯å¦æƒ³è¦è¾“å…¥ '{suggestions[first_token]}' è€Œä¸æ˜¯ '{first_token}'?")
        else:
            print(f"ğŸ’¡ æç¤º: æ— æ³•è¯†åˆ«çš„SQLå…³é”®å­— '{first_token}'")
            print("   æ”¯æŒçš„SQLè¯­å¥ç±»å‹:")
            print("   - SELECT: æŸ¥è¯¢æ•°æ®")
            print("   - INSERT: æ’å…¥æ•°æ®") 
            print("   - UPDATE: æ›´æ–°æ•°æ®")
            print("   - DELETE: åˆ é™¤æ•°æ®")
            print("   - CREATE: åˆ›å»ºè¡¨/ç´¢å¼•")
            print("   - DROP: åˆ é™¤è¡¨/ç´¢å¼•")
    
    def _parse_select(self) -> Optional[ASTNode]:
        """è§£æSELECTè¯­å¥"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤æ‚æŸ¥è¯¢
        is_complex = self._is_complex_query()
        
        try:
            if is_complex:
                parser = ExtendedParser(self.tokens)
            else:
                parser = Parser(self.tokens)
            
            return parser.parse()
        except SyntaxError as e:
            # é‡æ–°æŠ›å‡ºè¯­æ³•é”™è¯¯ï¼Œä¿ç•™è¯¦ç»†ä¿¡æ¯
            raise e
        except Exception as e:
            raise SyntaxError(f"SELECTè¯­å¥è§£æå¤±è´¥: {e}")
    
    def _parse_ddl(self) -> Optional[ASTNode]:
        """è§£æDDLè¯­å¥"""
        parser = DDLParser(self.tokens)
        return parser.parse()
    
    def _parse_dml(self) -> Optional[ASTNode]:
        """è§£æDMLè¯­å¥"""
        parser = DMLParser(self.tokens)
        return parser.parse()
    
    def _is_complex_query(self) -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºå¤æ‚æŸ¥è¯¢
        
        Returns:
            æ˜¯å¦ä¸ºå¤æ‚æŸ¥è¯¢
        """
        complex_keywords = {
            'JOIN', 'INNER', 'LEFT', 'RIGHT', 'FULL',
            'COUNT', 'SUM', 'AVG', 'MAX', 'MIN',
            'GROUP', 'ORDER', 'HAVING', 'ASC', 'DESC',
            'LIMIT', 'OFFSET'
        }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¤æ‚æŸ¥è¯¢å…³é”®å­—
        for token in self.tokens:
            if token.value.upper() in complex_keywords:
                return True
                
        # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨åˆ«å.åˆ—åçš„å½¢å¼ï¼ˆç‚¹å·ï¼‰
        for i, token in enumerate(self.tokens):
            if (token.type == TokenType.DOT and 
                i > 0 and i < len(self.tokens) - 1 and
                self.tokens[i-1].type == TokenType.IDENTIFIER and
                self.tokens[i+1].type == TokenType.IDENTIFIER):
                return True
                
        return False
    
    def get_sql_type(self) -> str:
        """è·å–SQLç±»å‹"""
        return self.sql_type or "UNKNOWN"
    
    def get_tokens(self) -> List[Token]:
        """è·å–Tokenåˆ—è¡¨"""
        return self.tokens


